\documentclass{article}

\title{Analyse II \\ Équations Différentielles \\ Anna Lachowska}
\author{Benjamin Bovey}
\date{Semestre de printemps 2019}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\usepackage{cancel}
\usepackage{url}

\theoremstyle{plain}
\newtheorem{thm}{Théorème}

\theoremstyle{definition}
\newtheorem{defn}[thm]{Définition}
\newtheorem{exmp}[thm]{Exemple}
\newtheorem*{anz}{Ansatz}

\theoremstyle{remark}
\newtheorem*{remark}{Remarque}
\newtheorem*{attention}{Attention}

\begin{document}

\section*{Introduction}
Résumé de la section sur les équations différentielles ordinaires, EDVS, EDL1 et EDL2 du cours d'Analyse II par Anna Lachowska. Retrouvez la page github contenant d'autres résumés et documents, accessibles et modifiables par toustes: \url{https://github.com/arakniode/almighty-handbook-of-sleep-deprived-student}

\section{Équation Différentielle}
\begin{defn}\label{def:equadiff}
Une équation différentielle ordinaire est une équation qui lie une fonction $y = y(x)$ à sa dérivée. Par exemple, l'équation
\begin{equation}
	y' + y = 0
\end{equation}
est une équation différentielle. 
\end{defn}
La solution d'une équation différentielle est une fonction ou un \textbf{ensemble de fonctions}, à la différence des équations "classiques" qui acceptent comme solution un nombre ou un ensemble de nombres. La réponse exigée à une équation différentielle est une \textbf{fonction réelle} ainsi que l'intervalle sur lequel elle est définie en tant que solution de l'équation différentielle.

\begin{attention}
	Parfois je noterai $y$ pour désigner la fonction $y(x)$.
\end{attention}

\subsection{Terminologie de base} % A AMELIORER (degre, ordre)
Ordre, degré, linéarité, solution générale, problème de Cauchy (conditions intiales) \\
\begin{defn} le \textbf{degré} d'une équation différentielle est l'exposant le plus haut sur un terme $y^{(n)}$. Par exemple, l'équation $y^2 = y'$ est une équation différentielle de degré 2. 
\end{defn}
\begin{defn} l'\textbf{ordre} d'une équation différentielle est de $n$ si l'équation contient un terme en $y^{(n)}$, et pas plus. Par exemple, $y = y''$ est une équation différentielle d'ordre 2.
\end{defn}
\begin{defn} la \textbf{solution générale} d'une équation différentielle est l'ensemble de toutes les solutions qui satisfont l'équation (sans conditions initiales)
\end{defn}
\begin{defn} la \textbf{solution maximale} d'une équation différentielle avec la condition initiale $y(x_0) = b_0$ est une fonction y(x) satisfaisant l'équation et la condition initiale, et définie sur le plus grand intervalle possible.
\end{defn}

%-------------------------------------------------------------------------------------

\section{Équation à variables séparées (EDVS)}
\begin{defn}\label{def:edvs}
Une équation différentielle est dite "à variable séparées" lorsqu'on peut placer tous les termes en $x$ d'un côté de l'équation, et tous les termes en $y$ de l'autre (n'oublions pas que $x$ est la \emph{variable} de la fonction $y$).
\end{defn}

\begin{exmp}
On peut réécrire l'équation différentielle de la définition \ref{def:equadiff} ainsi:
	\begin{align*}
		y' + y &= 0 \\
		y' &= -y \\
\intertext{On employe la notation de Leibniz, qui permet notamment de séparer les variables:}
		\dfrac{dy}{dx} &= -y \\
		\dfrac{dy}{y} &= -dx \\
\intertext{On peut désormais intégrer les deux côtés de l'équation, et résoudre pour $y$:}
		\int \dfrac{dy}{y} &= -\int dx \\
		log(y) + C_1 &= -x + C_2 \\
		e^{\log(y) + C_1} &= e^{-x + C_2} \\
		e^{C_1} \cdot y &= e^{C_2} \cdot e^{-x} \\
		y &= e^{C_2 - C_1} \cdot e^{-x} \\
\intertext{Renommons $e^{C_2 - C_1}$ (qui n'est qu'une constante) en $C$:}
		y &= Ce^{-x}
\end{align*}

C'est la solution générale de l'équation différentielle. Ici, on voit qu'il existe une infinité de fonctions (pour chaque $C \in \mathbb{R}$) qui satisfont cette équation.
\end{exmp}

\begin{thm}[existence et unicité d'une solution de EDVS]
Toute équation différentielle à variables séparées avec une condition initiale: $y(x_0) = b_0$ possède une unique solution $y$.
\end{thm}
\begin{attention} la démonstration \underline{de l'existence} (à retrouver dans les notes) peut être demandée à l'examen! Idée: $f(y)y' = g(x) \iff f(y)\frac{dy}{dx} = g(x) \iff \int f(y)dy = \int f(x)dx \iff F(y) = G(x)$. Puis, remarquer que $F(y)$ est inversible sur l'intervalle de définition de $f(y)$
\end{attention}

\begin{exmp}
	\begin{align*}
		&\dfrac{y'(x)}{y^2(x)} = 1 \implies \int \dfrac{dy}{y^2} = \int dx \implies -\dfrac1y = x + C \ ,\forall C \in \mathbb{R} \\
		&\implies y = -\dfrac{1}{x + C} \ ,\forall C \in \mathbb{R} \quad \text{(solution générale)} \\
\intertext{Supposons qu'on cherche une solution telle que $y(0) = b_0 \in \mathbb{R}$}
		&\implies y(0) = -\dfrac1C = b_0 \implies C = -\dfrac{1}{b_0} \implies y(x) = -\dfrac{1}{x - \frac{1}{b_0}} \\
		&= \dfrac{b_0}{1 - xb_0} \\
		&\text{Si $b_0 > 0$}	\implies \dfrac{1}{b_0} > 0 \implies y(x) = -\dfrac{1}{x - \frac{1}{b_0}} \text{ sur } \mathopen]-\infty, \frac{1}{b_0}\mathclose[
	\end{align*}
Il s'agit là de la solution particulière si $b_0 > 0$. On peut également calculer la solution particulière pour $b_0 < 0$, qui sera définie sur un autre intervalle.
\end{exmp}

%-------------------------------------------------------------------------------------

\section{Equation différentielle linéaire de premier ordre (EDL1)}
\begin{defn}
Une équation différentielle linéaire de premier ordre est une équation de la forme
	\begin{equation}
		y'(x) + p(x)y(x) = f(x)
	\end{equation}
\end{defn}

Considérons l'équation:
\begin{equation}
	y'(x) + p(x)y(x) = 0
\end{equation}
Elle s'appelle l'\textbf{équation homogène associée} à l'EDL1 précédente. \\
Tout d'abord, on voit que $y(x) = 0$ est une solution $\forall x \in \mathbb{R}$. Mettons de côté cette solution triviale en divisant par $y$. On se retrouve avec l'équation
\begin{align*}
	\dfrac{y'(x)}{y(x)} = -p(x) \\
\intertext{qui est une EDVS, donc}
	\int \dfrac{dy}{y} = -\int p(x)dx
\end{align*}

\subsection{Méthode de la variation de constante}
On cherche une solution particulière de $y + p(x) y = f(x) \ , p, f : I \to \mathbb{R}$ sous la forme:
\begin{anz} $v(x) = C(x) e^{-P(x)}$ \quad où $P(x)$ est une primitive de $p(x)$ sur $I$
\end{anz}

Si $v(x)$ est une solution de l'équation:
\begin{align*}
	\implies v'(x) + p(x)v(x) = f(x) \implies c'(x) e^{-P(x)} + c(x) e^{-P(x)}(-p(x)) + p(x)c(x)e^{-P(x)} = f(x) \\
	\implies c'(x) = f(x)e^{P(x)} \implies c(x) = \int f(x) e^{P(x)} dx
\end{align*}
$\implies$ une solution particulière de l'équation $y'(x) + p(x) y(x) = f(x)$ est $v(x) = \bigr( \int f(x) e^{P(x)} dx \bigl)\cdot e^{-P(x)}$ où $P(x)$ est \underline{une} primitive de p(x) sur $I$.

\begin{exmp}
	\begin{align*}
		&y' + y = 5x + 1, \quad p(x) = 1, f(x) = 5x + 1 \\
		&P(x) = \int 1 dx = x \quad \text{(une primitive, sans constante)} \\
\intertext{La solution générale de l'équation homogène associée: $y' + y = 0$ est $y(x) = Ce^{-P(x)} = Ce^{-x} \ ,\forall C, x \in \mathbb{R}$}
\intertext{pour trouver une solution particulière de l'équation $y' + y = 5x + 1$ on calcule}
		&c(x) = \int f(x) e^{P(x)} dx = \int (5x + 1) e^x dx = 5 \int x e^x dx + \int e^x dx \\
		&= 5xe^x - 5 \int e^x dx + \int e^x dx  = \underbrace{5xe^x - 4e^x + 1}_{\substack{\text{on ne peut choisir} \\ \text{une constante arbitraire}}} \\
\intertext{Une solution particulière de $y' + y = 5x + 1$ est}
		&v(x) = (5xe^x - 4e^x - 1)e^{-x} = \underbrace{5x - 4 + e^{-x}}_{\substack{\text{une solution} \\ \text{particulière}}}
\intertext{Vérification:}
		&v'(x) + v(x) = 5 - \cancel{e^{-x}} + 5x - 4 + \cancel{e^{-x}} = 5x + 1 = f(x)
\end{align*}
\end{exmp}

\begin{thm} Soient $p, f \to \mathbb{R}$ deux fonction continues. Supposons que $v_0 : I \to \mathbb{R}$ est une solution particulière de l'équation $y'(x) + p(x)y(x) = f(x)$. Alors la solution générale de cette équation est
\begin{equation}
	v(x) = v_0(x) + Ce^{-P(x)}
\end{equation}
$\forall C \in \mathbb{R}$, \ où $P(x)$ est \underline{une} primitive de $p(x)$ sur $I$.
\end{thm}

\subsection{Solution générale d'une EDL1}
\begin{thm}
La solution générale de l'EDL1 $y' + p(x)y = f(x)$ est:
\begin{equation}
	y(x) = C \cdot e^{-P(x)} + \bigl( f(x) e^{P(x)} dx\bigr) e^{-P(x)}
\end{equation}
où $P(x)$ est \underline{une} intégrale de $p(x)$ (donc pas besoin d'inclure la constante d'intégration).
\end{thm}

\section{25 février 2019}
\subsection{Équation de Bernouilli}
\begin{defn}
Une équation différentielle de la forme $y' + p(x)y = q(x) y^\alpha$, où $p, q: I \to \mathbb R$ fonctions continues et $\alpha \in \mathbb R, \alpha \neq 0, 1$, est dite l'équation de Bernouilli.
\end{defn}
On peut la transformer en EDL1 par le changement de variable $z(x) = (y(x))^{1-\alpha}$. Cela nous permet d'arriver à l'EDL 1 $\frac{1}{1-\alpha}z'(x) + p(x)z(x) = q(x)$.

\begin{exmp} $y'(x) = \frac4x y + x \sqrt{y} \iff y'(x) - \frac4x y = x\sqrt{y} \implies x \neq 0, y(x) \geq 0$.
\begin{flalign*}
\intertext{Changement de variable: $z(x) = (y(x))^{1-\alpha} = \sqrt y$}
	&\implies z'(x) = \frac{1}{2 \sqrt y} \cdot y' = \frac12 \frac{y'}{\sqrt y} \implies \ldots 
	\implies  z' - \underbrace{\frac 2x}_{p(x)} z = \underbrace{\frac x2}_{f(x)} \quad \text{(EDL1)} \\
\intertext{On cherche la solution générale de l'équation homogène associée:}
	&P(x) = -\int \frac{2dx}{x} = -2\log|x| = -\log(x^2), \quad x \neq 0 \quad \text{(pas de constante)} \\
	&\implies z_{\text{hom}}(x) = Ce^{-P(x)} = Ce^{\log(x^2)} = Cx^2, \quad x \neq 0
\intertext{On cherche une solution particulière de l'équation complète:}
	&z' - \frac2x z = \underbrace{\frac x2}_{f(x)} \\
	&\int f(x) e^{P(x)} dx = \ldots = \frac12 \log|x|, x \neq 0 \quad \text{(pas de constante)} \\
	&\implies z_{\text{part}}(x) = \frac12 \log|x| \cdot e^{\log(x^2)} = \frac12 x^2 \log|x|, \quad x \neq 0
\intertext{Solution générale de l'EDL1:}
	& z(x) = \left \{ \begin{aligned}
		&Cx^2 + \frac{x^2}{2} \log(x), & & x \in \mathopen]0, \infty \mathclose[, C \in \mathbb R \\
		&Cx^2 + \frac{x^2}{2} \log(-x), & & x \in \mathopen]-\infty, 0 \mathclose[, C \in \mathbb R
	\end{aligned}
	\right .
\intertext{Solution générale de l'équation originale  avec $y(x) = z^2(x)$:}
	&y(x) = \left\{ \begin{aligned}
	&x^4(C + \frac12 \log(x))^2, & & x \in \mathopen]0, + \infty \mathclose[ \ , C \in \mathbb R \\
	&x^4(C + \frac12 \log(-x))^2, & & x \in \mathopen]- \infty, 0 \mathclose[ \ , C \in \mathbb R \\
	&0, & & x \in \mathopen]0, +\infty \mathclose[ \\
	&0, & & x \in \mathopen]-\infty, 0 \mathclose[
	\end{aligned}
	\right .
\end{flalign*}
\end{exmp}

\section{Trucs vraiment utiles pour equa diff}
\begin{defn}[EDL1]
Une équation différentielle linéaire de degré 1 (EDL1) est une équation de la forme
	\begin{equation*}
		y' + p(x)y = f(x)
	\end{equation*}
Une équation différentielle linéaire homogène de degré 1 (EDLH1) est une équation de la forme
	\begin{equation*}
		y' + p(x)y = 0
	\end{equation*}
Une équation différentielle linéaire de degré 1 \textbf{à coefficients constants} est une équation de la forme
	\begin{equation*}
		y' + py = f(x), \text{ où } p \in \mathbb R
	\end{equation*}
\end{defn}


\begin{thm}[Solution particulière EDL1]
	\begin{equation}
		\Biggl( \int f(x)e^{P(x)} dx \Biggr) \cdot e^{-P(x)}
	\end{equation}
\end{thm}

\begin{thm}[Solution générale EDLH1]
	\begin{equation}
		y = Ce^{-P(x)}
	\end{equation}
\end{thm}

\begin{thm}[Solution générale EDL1]
La solution générale d'une EDL1 est la somme d'une solution particulière et de la solution générale de l'équation homogène associée.
	\begin{equation}
		y = Ce^{-P(x)} + \Biggl( \int f(x)e^{P(x)}dx \Biggr) \cdot e^{-P(x)}
	\end{equation}
\end{thm}

\begin{defn}[EDL2]
	Une équation différentielle linéaire de degré 2 (EDL2) est une équation de la forme
	\begin{equation*}
		y'' + p(x)y' + q(x)y = f(x)
	\end{equation*}
	Une équation différentielle linéaire homogène de degré 2 (EDLH2) est une équation de la forme
	\begin{equation*}
		y'' + p(x)y' + q(x)y = 0
	\end{equation*}
	Une équation différentielle linéaire de degré 2 à coefficients constantes est une équation de la forme
	\begin{equation*}
		y'' + py' + qy = f(x), \text{ où } p, q \in \mathbb R
	\end{equation*}
\end{defn}

\begin{thm}[Solution générale EDLH2 à coefficients constants]
	\begin{equation}
		C_1 e^{ax} + C_2 e^{bx},
	\end{equation}
où $a, b \in \mathbb R$ sont les racines du polynôme $\lambda^2 + p\lambda + q = 0$.
\end{thm}

\section{4 mars 2019}

\subsection{Lien avec l'algèbre linéaire}
On peut parler de solutions linéairement indépendantes à l'EDLH2. Pour déterminer si deux solution d'une EDLH2 sont linéairement indépendantes, on peut utiliser l'outil mathématique suivant, qui utilise des notions d'algèbre linéaire.
\begin{defn}
On définit la fonction $W[v_1, v_2]$, où $v_1, v_2$ sont deux fonctions dérivables sur $I \subseteq \mathbb R$, par:
	\begin{equation}
		W[v_1, v_2] = \det \begin{pmatrix}
			v_1(x) & v_2(x) \\
			v_1'(x) & v_2'(x)
		\end{pmatrix}
	\end{equation}
	Cette fonction s'appelle le \textbf{Wronskien} de $v_1$ et $v_2$.
\end{defn}

\begin{exmp}
Considérons l'EDLH2 à coefficients constants suivante:
	\begin{align*}
		&y'' + 2y' + y = 0 \\
	\intertext{La solution générale est de la forme:}
		&C_1 e^{-x} + C_2 e^{-x} \quad \text{où } C_1, C_2 \in \mathbb R \\
		&\implies W[e^{-x}, e^{-x}] = \det \begin{pmatrix}
			e^{-x} & e^{-x} \\
			-e^{-x} & -e^{-x}
			\end{pmatrix} = e^{-2x} - \cancel{xe^{-2x}} + \cancel{xe^{-2x}} = e^{-2x}
	\end{align*}
\end{exmp}

\begin{thm}[indépendance linéaire de deux solutions d'une EDL2]
	Soient $v_1, v_2 : I \to \mathbb R$ deux solutions d'une EDL2. Alors
	\begin{equation}
		\underbrace{v_1(x) \text{ et } v_2(x) \text{ sont linéairement indépendantes}}_{P} \iff \underbrace{W[v_1, v_2](x) \neq 0 \ \forall x \in I}_{Q}
	\end{equation}
\end{thm}

En réfléchissant un peu, on peut donner un argument assez intuitif quant à l'utilisation de cet outil étrange. En effet, l'algèbre linéaire permet de montrer que:
\begin{enumerate}
	\item le fait que les colonnes d'une matrices soient linéairement dépendantes est logiquement équivalent au fait que le noyau de la matrice n'est pas nul, et que
	\item le fait que le noyau n'est pas nul est logiquement équivalent au fait que le déterminant est 0. Donc:
	\item les colonnes d'une matrice sont linéairement dépendantes $\iff$ le déterminant de la matrice est 0
\end{enumerate}
 En gardant ceci en tête, considérons la double implication du théorème. \\
Premièrement, si $\neg Q$ est vrai, c'est-à-dire s'il existe un point sur $I$ tel que le déterminant est nul, alors $\neg P$ est vrai, c'est-à-dire que $v_1(x)$ et $v_2(x)$ sont linéairement dépendantes ($\neg Q \implies \neg P \equiv P \implies Q$). \\ Deuxièmement, si $Q$ est vrai, c'est-à-dire que le déterminant n'est jamais 0, alors le noyau n'est pas nul, et donc les colonnes sont linéairement indépendantes, ce qui veut dire que $P$ est vrai ($Q \implies P$). \\
Il s'agit ici bien sûr uniquement d'un argument et non d'une preuve, mais je considère cet argument bien plus parlant que la preuve formelle présentée en cours. \par
L'élément qui reste peut-être étrange est l'inclusion des dérivées de $v_1$ et $v_2$. Pour comprendre ceci, il faut se rappeler du fait que la différentiation est en fait un opérateur linéaire, et donc qui préserve l'indépendance/dépendance linéaire. Donc, afin de pouvoir faire une matrice carrée et donc pouvoir calculer son déterminant, on inclut également les dérivées des fonctions. Le Wronskien étant un outil, et non un théorème, il faut se rendre compte qu'il a été \emph{conçu} (et non pas découvert au sens plus général du terme) pour bien \emph{fonctionner}, et que les choix faits lors de sa construction ne sont pas toujours les plus intuitifs, mais plutôt les plus pratiques.

\begin{thm}[solution générale d'une EDL2]
	Soient $v_1, v_2 : I \to \mathbb R$ deux solutions linéairement indépendantes d'une EDL2. Alors la solution générale de cette équation est de la forme
	\begin{equation}
		v(x) = C_1 v_1(x) + C_2 v_2(x),
	\end{equation}
où $C_1, C_2 \in \mathbb R, x \in I$.
\end{thm}

\begin{thm}
	Soient $v$ une solution d'une EDL2, et $u$ une solution de l'EDLH2 associée. Alors
	\begin{equation}
		v(x) + u(x)
	\end{equation}
	est une solution générale de l'EDL2.
\end{thm}

\section{6 mars 2019}

\begin{defn}
	La \textbf{méthode de variation des constantes} est une méthode qui permet souvent de trouver une solution particulière à une EDLH2.
\end{defn}

\begin{defn}
	La \textbf{méthode des coefficients indéterminés} est une méthode qui permet parfois de trouver une solution particulière à une EDL2 à coefficients constants. \textbf{ATTENTION} Il y a presque toujours une EDL2 à coeff constant "piège" à l'exa où il faut utiliser cette méthode.
\end{defn}

\begin{exmp}[méthode des coefficients indéterminés]
\begin{align*}
	&2y'' - y' - y = 100xe^{2x}
\intertext{Equation homogène associée:}
	&y'' - \frac12 y' - \frac12 y = 0 \implies \lambda^2 - \frac12 \lambda - \frac12 = 0 \implies \lambda_1 = 1, \lambda_2 = -\frac12 \\
\intertext{Solution générale de l'équation homogène:}
	&y_{\text{hom}} = C_1e^x + C_2e^{-\frac{x}{2}}, C_1, C_2 \in \mathbb R, x \in \mathbb R. \\
\intertext{Solution particulière de l'équation complète (méthode des coefficients indéterminés):}
	&y'' - \frac12 y' - \frac12 y = 50xe^{2x} \implies f(x) = 50xe^{2x} \text{ de la forme } e^{ax}P_n(x), \text{ où } n = 1. \\
\intertext{La méthode s'applique. $a = 2$ est-il une solution de l'équation caractéristique? Non. Alors l'Ansatz est:}
	&y_{\text{part}} = (Ax + B)e^{2x} \implies \text{remplacer dans l'équation} \\
	&y_p' = Ae^{2x} + 2(Ax + B)e^{2x}; \quad y_p'' = 2Ae^{2x} + 2Ae^{2x} + 4(Ax + B)e^{2x} \\
	&\implies \underbrace{5Ae^{2x} + 4(Ax + B)e^{2x}}_{y_p''}
			 	- \frac12 \underbrace{Ae^{2x} - (Ax + B)e^{2x}}_{y_p'}
				- \frac12 \underbrace{(Ax + B)e^{2x} = 50xe^{2x}}_{y_p} \\
	&\implies xe^{2x}(\frac52 A) + e^{2x}(\frac72 A + \frac52 B) = 50xe^{2x} \\
	&\implies \begin{cases}
					\frac52 A = 50 \\
					\frac72 A + \frac52 B = 0
				\end{cases} \implies \begin{cases}
					A = 20 \\
					B = -28
				\end{cases} \\
	&\implies y_{\text{part}}(x) = (20x - 28)e^{2x} \\
\intertext{La solution générale de $2y'' - y' - y = 100xe^{2x}$ est}
	&\boxed{y(x) = C_1e^x + C_2e^{-\frac{x}{2}} + (20x - 28)e^{2x}} \quad, C_1, C_2 \in \mathbb R, x \in \mathbb R
\end{align*}
\end{exmp}

\begin{remark}
	Si $f(x) = f_1(x) + f_2(x)$, où $f_1(x)$ est de la forme $e^{ax} P_n(x)$ et $f_2(x)$ est de la forme $e^{ax}(P_n(x) cos(bx) + Q_m(x) sin(bx))$, alors on utilise la méthode pour $f_1(x)$ et $f_2(x)$ séparément, obtenir $y_{\text{part, 1}}(x)$ et $y_{\text{part, 2}}(x)$, et utiliser le principe de superposition des solutions:
\begin{equation*}
	y_{\text{part}}(x) = y_{\text{part, 1}}(x) + y_{\text{part, 2}}(x).
\end{equation*}
\end{remark}






\end{document}